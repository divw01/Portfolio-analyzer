{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b373d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- CODE CELL 1: Imports + Config + Functions (functions first) ---\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "\n",
    "ALPHAVANTAGE_API_KEY = \"OYA0CFIEESAINF1M\"\n",
    "AV_BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "SECURITY_MASTER_DIR = DATA_DIR / \"security_master\"\n",
    "ETF_HOLDINGS_DIR = DATA_DIR / \"etf_holdings\"\n",
    "OVERRIDES_DIR = DATA_DIR / \"overrides\"\n",
    "\n",
    "SECURITY_MASTER_PARQUET = SECURITY_MASTER_DIR / \"security_master.parquet\"\n",
    "SECURITY_MASTER_META = SECURITY_MASTER_DIR / \"meta.json\"\n",
    "ASSET_OVERRIDES_CSV = OVERRIDES_DIR / \"asset_overrides.csv\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def ensure_dirs():\n",
    "    SECURITY_MASTER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    ETF_HOLDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OVERRIDES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def now_ts() -> str:\n",
    "    return dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def today_str() -> str:\n",
    "    return dt.date.today().isoformat()\n",
    "\n",
    "def symbol_norm(symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize ticker symbols for joining across sources.\n",
    "\n",
    "    Rules (simple + practical):\n",
    "    - uppercase, strip\n",
    "    - replace '.' and '/' with '-'\n",
    "    - collapse consecutive '-' into one\n",
    "    \"\"\"\n",
    "    if symbol is None:\n",
    "        return \"\"\n",
    "    s = str(symbol).upper().strip()\n",
    "    s = s.replace(\".\", \"-\").replace(\"/\", \"-\")\n",
    "    s = re.sub(r\"-{2,}\", \"-\", s)\n",
    "    return s\n",
    "\n",
    "def safe_float(x) -> Optional[float]:\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            x = x.replace(\"$\", \"\").replace(\",\", \"\").strip()\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_market_cap(x) -> Optional[float]:\n",
    "    return safe_float(x)\n",
    "\n",
    "def parse_last_sale(x) -> Optional[float]:\n",
    "    return safe_float(x)\n",
    "\n",
    "def alpha_vantage_get(params: Dict[str, Any], timeout: int = 30) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Alpha Vantage GET wrapper.\n",
    "    Notes:\n",
    "    - AV sometimes returns \"Note\" (rate limit) or \"Information\" (errors).\n",
    "    \"\"\"\n",
    "    params = dict(params)\n",
    "    params[\"apikey\"] = ALPHAVANTAGE_API_KEY\n",
    "    r = requests.get(AV_BASE_URL, params=params, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    if isinstance(data, dict) and (\"Note\" in data or \"Information\" in data or \"Error Message\" in data):\n",
    "        raise RuntimeError(f\"Alpha Vantage response indicates an issue: {data}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Overrides (Stock vs ETF)\n",
    "# =========================\n",
    "\n",
    "def load_asset_overrides() -> pd.DataFrame:\n",
    "    ensure_dirs()\n",
    "    if ASSET_OVERRIDES_CSV.exists():\n",
    "        df = pd.read_csv(ASSET_OVERRIDES_CSV)\n",
    "        if \"ticker_norm\" not in df.columns and \"ticker\" in df.columns:\n",
    "            df[\"ticker_norm\"] = df[\"ticker\"].map(symbol_norm)\n",
    "        if \"is_etf\" not in df.columns:\n",
    "            df[\"is_etf\"] = False\n",
    "        df[\"ticker_norm\"] = df[\"ticker_norm\"].astype(str).map(symbol_norm)\n",
    "        df[\"is_etf\"] = df[\"is_etf\"].astype(bool)\n",
    "        df = df.drop_duplicates(subset=[\"ticker_norm\"], keep=\"last\")\n",
    "        return df[[\"ticker_norm\", \"is_etf\"]]\n",
    "    return pd.DataFrame(columns=[\"ticker_norm\", \"is_etf\"])\n",
    "\n",
    "def save_asset_overrides(overrides_df: pd.DataFrame) -> None:\n",
    "    ensure_dirs()\n",
    "    out = overrides_df.copy()\n",
    "    if \"ticker_norm\" not in out.columns:\n",
    "        raise ValueError(\"Overrides must include ticker_norm\")\n",
    "    if \"is_etf\" not in out.columns:\n",
    "        raise ValueError(\"Overrides must include is_etf\")\n",
    "    out[\"ticker_norm\"] = out[\"ticker_norm\"].astype(str).map(symbol_norm)\n",
    "    out[\"is_etf\"] = out[\"is_etf\"].astype(bool)\n",
    "    out = out.drop_duplicates(subset=[\"ticker_norm\"], keep=\"last\")\n",
    "    out.to_csv(ASSET_OVERRIDES_CSV, index=False)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Security Master (Nasdaq Screener CSV)\n",
    "# =========================\n",
    "\n",
    "REQUIRED_MASTER_COLS = {\"Symbol\", \"Name\", \"Country\", \"Sector\", \"Industry\"}\n",
    "\n",
    "def load_security_master() -> pd.DataFrame:\n",
    "    ensure_dirs()\n",
    "    if SECURITY_MASTER_PARQUET.exists():\n",
    "        df = pd.read_parquet(SECURITY_MASTER_PARQUET)\n",
    "        if \"symbol_norm\" not in df.columns and \"Symbol\" in df.columns:\n",
    "            df[\"symbol_norm\"] = df[\"Symbol\"].map(symbol_norm)\n",
    "        return df\n",
    "    return pd.DataFrame(columns=[\"Symbol\",\"Name\",\"Country\",\"Sector\",\"Industry\",\"symbol_norm\"])\n",
    "\n",
    "def refresh_security_master_from_csv(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the Nasdaq Stock Screener CSV and persists a cleaned version as parquet.\n",
    "    Keeps the raw CSV with timestamp so users can roll back if needed.\n",
    "    \"\"\"\n",
    "    ensure_dirs()\n",
    "    raw_path = Path(csv_path)\n",
    "    if not raw_path.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found at: {csv_path}\")\n",
    "\n",
    "    raw_copy = SECURITY_MASTER_DIR / f\"raw_{now_ts()}.csv\"\n",
    "    raw_copy.write_bytes(raw_path.read_bytes())\n",
    "\n",
    "    df = pd.read_csv(raw_copy)\n",
    "\n",
    "    missing = REQUIRED_MASTER_COLS - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Security master CSV is missing required columns: {sorted(list(missing))}\")\n",
    "\n",
    "    keep_cols = [c for c in [\"Symbol\",\"Name\",\"Last Sale\",\"Market Cap\",\"Country\",\"IPO Year\",\"Volume\",\"Sector\",\"Industry\"] if c in df.columns]\n",
    "    df = df[keep_cols].copy()\n",
    "\n",
    "    df[\"Symbol\"] = df[\"Symbol\"].astype(str).str.strip()\n",
    "    df[\"symbol_norm\"] = df[\"Symbol\"].map(symbol_norm)\n",
    "\n",
    "    if \"Last Sale\" in df.columns:\n",
    "        df[\"last_sale_num\"] = df[\"Last Sale\"].map(parse_last_sale)\n",
    "    if \"Market Cap\" in df.columns:\n",
    "        df[\"market_cap_num\"] = df[\"Market Cap\"].map(parse_market_cap)\n",
    "\n",
    "    df = df[df[\"symbol_norm\"] != \"\"].copy()\n",
    "\n",
    "    if \"market_cap_num\" in df.columns:\n",
    "        df = df.sort_values([\"symbol_norm\",\"market_cap_num\"], ascending=[True, False])\n",
    "    df = df.drop_duplicates(subset=[\"symbol_norm\"], keep=\"first\")\n",
    "\n",
    "    df.to_parquet(SECURITY_MASTER_PARQUET, index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"uploaded_at\": dt.datetime.now().isoformat(),\n",
    "        \"raw_copy\": str(raw_copy),\n",
    "        \"row_count\": int(len(df)),\n",
    "        \"columns\": list(df.columns),\n",
    "    }\n",
    "    SECURITY_MASTER_META.write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ETF Holdings Cache (Alpha Vantage ETF_PROFILE)\n",
    "# =========================\n",
    "\n",
    "def holdings_cache_path(etf_symbol: str, asof_date: Optional[str] = None) -> Path:\n",
    "    ensure_dirs()\n",
    "    etf = symbol_norm(etf_symbol)\n",
    "    d = asof_date or today_str()\n",
    "    folder = ETF_HOLDINGS_DIR / etf\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    return folder / f\"holdings_{d}.parquet\"\n",
    "\n",
    "def load_cached_etf_holdings(etf_symbol: str, asof_date: Optional[str] = None) -> Optional[pd.DataFrame]:\n",
    "    path = holdings_cache_path(etf_symbol, asof_date)\n",
    "    if path.exists():\n",
    "        return pd.read_parquet(path)\n",
    "    return None\n",
    "\n",
    "def refresh_etf_holdings(etf_symbol: str, asof_date: Optional[str] = None, sleep_seconds: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches ETF holdings from Alpha Vantage ETF_PROFILE and caches a daily snapshot.\n",
    "    \"\"\"\n",
    "    etf_symbol = symbol_norm(etf_symbol)\n",
    "    d = asof_date or today_str()\n",
    "\n",
    "    data = alpha_vantage_get({\"function\": \"ETF_PROFILE\", \"symbol\": etf_symbol})\n",
    "\n",
    "    holdings = None\n",
    "    for k in [\"holdings\", \"Holdings\", \"constituents\", \"Constituents\"]:\n",
    "        if k in data and isinstance(data[k], list):\n",
    "            holdings = data[k]\n",
    "            break\n",
    "\n",
    "    if holdings is None:\n",
    "        for v in data.values():\n",
    "            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], dict):\n",
    "                keys = {k.lower() for k in v[0].keys()}\n",
    "                if any(k in keys for k in [\"symbol\",\"ticker\",\"holding\",\"asset\",\"constituent\"]) and any(k in keys for k in [\"weight\",\"allocation\",\"percentage\",\"pct\"]):\n",
    "                    holdings = v\n",
    "                    break\n",
    "\n",
    "    if holdings is None:\n",
    "        raise ValueError(f\"Could not locate holdings list in ETF_PROFILE response for {etf_symbol}. Keys: {list(data.keys())}\")\n",
    "\n",
    "    hdf = pd.DataFrame(holdings).copy()\n",
    "\n",
    "    lower_cols = {c: c.lower() for c in hdf.columns}\n",
    "    sym_candidates = [c for c in hdf.columns if lower_cols[c] in [\"symbol\",\"ticker\",\"holding\",\"asset\",\"constituent\"]]\n",
    "    wt_candidates = [c for c in hdf.columns if any(x in lower_cols[c] for x in [\"weight\",\"allocation\",\"percentage\",\"pct\"])]\n",
    "\n",
    "    if not sym_candidates:\n",
    "        sym_candidates = [c for c in hdf.columns if \"sym\" in lower_cols[c]]\n",
    "    if not wt_candidates:\n",
    "        wt_candidates = [c for c in hdf.columns if \"weight\" in lower_cols[c] or \"alloc\" in lower_cols[c] or \"pct\" in lower_cols[c]]\n",
    "\n",
    "    if not sym_candidates or not wt_candidates:\n",
    "        raise ValueError(f\"Could not infer holdings symbol/weight columns for {etf_symbol}. Columns: {list(hdf.columns)}\")\n",
    "\n",
    "    sym_col = sym_candidates[0]\n",
    "    wt_col = wt_candidates[0]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"etf_symbol\": etf_symbol,\n",
    "        \"constituent_symbol_raw\": hdf[sym_col].astype(str).str.strip(),\n",
    "        \"constituent_symbol_norm\": hdf[sym_col].astype(str).map(symbol_norm),\n",
    "        \"weight_raw\": hdf[wt_col],\n",
    "    })\n",
    "\n",
    "    out[\"weight\"] = out[\"weight_raw\"].map(safe_float)\n",
    "    if out[\"weight\"].notna().any():\n",
    "        if out[\"weight\"].dropna().median() > 1.0:\n",
    "            out[\"weight\"] = out[\"weight\"] / 100.0\n",
    "\n",
    "    out = out.dropna(subset=[\"constituent_symbol_norm\",\"weight\"])\n",
    "    out = out[out[\"constituent_symbol_norm\"] != \"\"].copy()\n",
    "\n",
    "    path = holdings_cache_path(etf_symbol, d)\n",
    "    out.to_parquet(path, index=False)\n",
    "\n",
    "    if sleep_seconds > 0:\n",
    "        time.sleep(sleep_seconds)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Portfolio normalization + look-through\n",
    "# =========================\n",
    "\n",
    "def normalize_portfolio_inputs(df: pd.DataFrame, total_portfolio_value: Optional[float] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Supported inputs:\n",
    "      - ticker (required)\n",
    "      - percent (optional; 0..1)\n",
    "      - shares (optional)\n",
    "      - price_per_share (optional)\n",
    "      - dollars (optional)\n",
    "\n",
    "    Compute position_value:\n",
    "      - dollars if provided\n",
    "      - else shares * price_per_share if available\n",
    "      - else percent * total_portfolio_value if provided\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    if \"ticker\" not in df.columns:\n",
    "        raise ValueError(\"Portfolio input must contain a 'ticker' column.\")\n",
    "\n",
    "    df[\"ticker_raw\"] = df[\"ticker\"].astype(str)\n",
    "    df[\"ticker_norm\"] = df[\"ticker_raw\"].map(symbol_norm)\n",
    "\n",
    "    if \"price_per_share\" not in df.columns:\n",
    "        df[\"price_per_share\"] = pd.NA\n",
    "\n",
    "    def compute_value(row):\n",
    "        if pd.notna(row.get(\"dollars\")):\n",
    "            return float(row[\"dollars\"])\n",
    "        if pd.notna(row.get(\"shares\")) and pd.notna(row.get(\"price_per_share\")):\n",
    "            return float(row[\"shares\"]) * float(row[\"price_per_share\"])\n",
    "        if pd.notna(row.get(\"percent\")):\n",
    "            if total_portfolio_value is None:\n",
    "                raise ValueError(\"total_portfolio_value must be provided if any row uses 'percent'.\")\n",
    "            return float(row[\"percent\"]) * float(total_portfolio_value)\n",
    "        return None\n",
    "\n",
    "    df[\"position_value\"] = df.apply(compute_value, axis=1)\n",
    "\n",
    "    bad = df[df[\"position_value\"].isna()]\n",
    "    if len(bad) > 0:\n",
    "        raise ValueError(\n",
    "            \"Some rows are missing enough info to compute dollars exposure. \"\n",
    "            \"Provide dollars OR shares+price_per_share OR percent+total_portfolio_value.\\n\"\n",
    "            f\"{bad[['ticker_raw','percent','shares','price_per_share','dollars']].to_string(index=False)}\"\n",
    "        )\n",
    "\n",
    "    # Keep is_etf if present\n",
    "    keep = [\"ticker_raw\",\"ticker_norm\",\"percent\",\"shares\",\"price_per_share\",\"dollars\",\"position_value\"]\n",
    "    if \"is_etf\" in df.columns:\n",
    "        keep.append(\"is_etf\")\n",
    "\n",
    "    return df[keep]\n",
    "\n",
    "def apply_etf_classification(portfolio_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Determines asset_type based on:\n",
    "    1) explicit portfolio_df.is_etf if present, else\n",
    "    2) saved overrides in data/overrides/asset_overrides.csv, else\n",
    "    3) default False\n",
    "    \"\"\"\n",
    "    df = portfolio_df.copy()\n",
    "    overrides = load_asset_overrides()\n",
    "\n",
    "    if \"is_etf\" not in df.columns:\n",
    "        df[\"is_etf\"] = pd.NA\n",
    "\n",
    "    df = df.merge(overrides, on=\"ticker_norm\", how=\"left\", suffixes=(\"\", \"_override\"))\n",
    "\n",
    "    # priority: explicit -> override -> False\n",
    "    df[\"is_etf_final\"] = df[\"is_etf\"]\n",
    "    df.loc[df[\"is_etf_final\"].isna(), \"is_etf_final\"] = df.loc[df[\"is_etf_final\"].isna(), \"is_etf_override\"]\n",
    "    df[\"is_etf_final\"] = df[\"is_etf_final\"].fillna(False).astype(bool)\n",
    "\n",
    "    df[\"asset_type\"] = df[\"is_etf_final\"].map(lambda x: \"ETF\" if bool(x) else \"Stock\")\n",
    "\n",
    "    drop_cols = [c for c in [\"is_etf_override\"] if c in df.columns]\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "def enrich_with_security_master(df: pd.DataFrame, master_df: pd.DataFrame, join_col: str) -> pd.DataFrame:\n",
    "    master_cols = [\"symbol_norm\",\"Name\",\"Country\",\"Sector\",\"Industry\"]\n",
    "    master_min = master_df[master_cols].drop_duplicates(\"symbol_norm\") if len(master_df) else pd.DataFrame(columns=master_cols)\n",
    "    out = df.merge(master_min, left_on=join_col, right_on=\"symbol_norm\", how=\"left\")\n",
    "    out = out.drop(columns=[\"symbol_norm\"])\n",
    "    return out\n",
    "\n",
    "def build_lookthrough_exposures(\n",
    "    portfolio_df: pd.DataFrame,\n",
    "    master_df: pd.DataFrame,\n",
    "    refresh_missing_etf_holdings: bool = True,\n",
    "    asof_date: Optional[str] = None,\n",
    "    per_etf_sleep_seconds: float = 0.0\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    d = asof_date or today_str()\n",
    "\n",
    "    for _, r in portfolio_df.iterrows():\n",
    "        src = r[\"ticker_norm\"]\n",
    "        src_type = r[\"asset_type\"]\n",
    "        pv = float(r[\"position_value\"])\n",
    "\n",
    "        if src_type == \"Stock\":\n",
    "            rows.append({\n",
    "                \"source_ticker_norm\": src,\n",
    "                \"source_type\": src_type,\n",
    "                \"underlying_symbol_norm\": src,\n",
    "                \"exposure_value\": pv,\n",
    "            })\n",
    "        else:\n",
    "            cached = load_cached_etf_holdings(src, d)\n",
    "            if cached is None and refresh_missing_etf_holdings:\n",
    "                cached = refresh_etf_holdings(src, d, sleep_seconds=per_etf_sleep_seconds)\n",
    "\n",
    "            if cached is None or len(cached) == 0:\n",
    "                rows.append({\n",
    "                    \"source_ticker_norm\": src,\n",
    "                    \"source_type\": src_type,\n",
    "                    \"underlying_symbol_norm\": None,\n",
    "                    \"exposure_value\": pv,\n",
    "                })\n",
    "            else:\n",
    "                for _, h in cached.iterrows():\n",
    "                    rows.append({\n",
    "                        \"source_ticker_norm\": src,\n",
    "                        \"source_type\": src_type,\n",
    "                        \"underlying_symbol_norm\": h[\"constituent_symbol_norm\"],\n",
    "                        \"exposure_value\": pv * float(h[\"weight\"]),\n",
    "                    })\n",
    "\n",
    "    exp = pd.DataFrame(rows)\n",
    "\n",
    "    exp = enrich_with_security_master(exp, master_df, join_col=\"underlying_symbol_norm\")\n",
    "\n",
    "    exp[\"company_name\"] = exp.get(\"Name\")\n",
    "    exp[\"country\"] = exp.get(\"Country\")\n",
    "    exp[\"sector\"] = exp.get(\"Sector\")\n",
    "    exp[\"industry\"] = exp.get(\"Industry\")\n",
    "\n",
    "    return exp\n",
    "\n",
    "def build_slices(exposures: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    by_company = (\n",
    "        exposures.dropna(subset=[\"underlying_symbol_norm\"])\n",
    "        .groupby([\"underlying_symbol_norm\",\"company_name\"], dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\",\"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    by_sector = (\n",
    "        exposures.groupby(\"sector\", dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\",\"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    by_country = (\n",
    "        exposures.groupby(\"country\", dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\",\"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    by_source_vehicle = (\n",
    "        exposures.groupby([\"source_ticker_norm\",\"source_type\"], dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\",\"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return by_company, by_sector, by_country, by_source_vehicle\n",
    "\n",
    "def find_unknown_underlyings(exposures: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Helps you see which tickers didn't match the local security master.\n",
    "    \"\"\"\n",
    "    df = exposures.copy()\n",
    "    df = df.dropna(subset=[\"underlying_symbol_norm\"])\n",
    "    unknown = df[df[\"company_name\"].isna()][[\"underlying_symbol_norm\"]].drop_duplicates()\n",
    "    unknown = unknown.sort_values(\"underlying_symbol_norm\").reset_index(drop=True)\n",
    "    return unknown\n",
    "\n",
    "def plot_bar(df: pd.DataFrame, category_col: str, value_col: str, title: str, top_n: int = 15):\n",
    "    if df is None or len(df) == 0:\n",
    "        print(f\"No data to plot for {title}\")\n",
    "        return\n",
    "    dd = df.copy()\n",
    "    dd = dd.dropna(subset=[category_col])\n",
    "    dd = dd.sort_values(value_col, ascending=False).head(top_n)\n",
    "    plt.figure()\n",
    "    plt.bar(dd[category_col].astype(str), dd[value_col].astype(float))\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(value_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "ensure_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- CODE CELL 2: App UI (ipywidgets) ---\n",
    "\n",
    "# -------------------------\n",
    "# UI State\n",
    "# -------------------------\n",
    "STATE = {\n",
    "    \"master\": load_security_master(),\n",
    "    \"portfolio_raw\": None,\n",
    "    \"portfolio_norm\": None,\n",
    "    \"portfolio_classified\": None,\n",
    "    \"exposures\": None,\n",
    "    \"slices\": None,\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# UI Widgets\n",
    "# -------------------------\n",
    "\n",
    "title = widgets.HTML(\"<h3>Portfolio Look-Through App</h3>\")\n",
    "\n",
    "instructions = widgets.HTML(\n",
    "    \"\"\"\n",
    "    <div style=\"line-height:1.35;\">\n",
    "      <b>1) Load / Refresh Security Master (Nasdaq Stock Screener CSV)</b><br>\n",
    "      Required columns: <code>Symbol, Name, Country, Sector, Industry</code>.<br>\n",
    "      This is used for slicing by country/sector/industry without paid APIs.<br><br>\n",
    "\n",
    "      <b>2) Load Portfolio</b><br>\n",
    "      Required: <code>ticker</code><br>\n",
    "      Provide ONE of:<br>\n",
    "      - <code>dollars</code> OR<br>\n",
    "      - <code>shares</code> + <code>price_per_share</code> OR<br>\n",
    "      - <code>percent</code> (0..1) + a <code>total_portfolio_value</code> in the UI<br><br>\n",
    "\n",
    "      Optional: <code>is_etf</code> (True/False). If not provided, you can set overrides below.\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Security master upload\n",
    "sm_upload = widgets.FileUpload(accept=\".csv\", multiple=False, description=\"Upload Security Master CSV\")\n",
    "sm_refresh_btn = widgets.Button(description=\"Refresh Security Master\", button_style=\"primary\")\n",
    "sm_status = widgets.Output()\n",
    "\n",
    "# Portfolio input: upload OR paste\n",
    "pf_upload = widgets.FileUpload(accept=\".csv\", multiple=False, description=\"Upload Portfolio CSV\")\n",
    "pf_template_btn = widgets.Button(description=\"Show Portfolio Template\", button_style=\"\")\n",
    "pf_paste = widgets.Textarea(\n",
    "    value=\"ticker,dollars,is_etf\\nAAPL,5000,False\\nQQQ,8000,True\\n\",\n",
    "    placeholder=\"Paste CSV here (header row required)\",\n",
    "    description=\"Or paste:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\")\n",
    ")\n",
    "pf_load_btn = widgets.Button(description=\"Load Portfolio\", button_style=\"primary\")\n",
    "pf_status = widgets.Output()\n",
    "\n",
    "total_value = widgets.FloatText(value=0.0, description=\"Total $ (if %):\", layout=widgets.Layout(width=\"300px\"))\n",
    "\n",
    "# ETF caching / refresh controls\n",
    "asof_date = widgets.Text(value=today_str(), description=\"As-of date:\", layout=widgets.Layout(width=\"260px\"))\n",
    "refresh_missing = widgets.Checkbox(value=True, description=\"Fetch missing ETF holdings (if not cached)\", indent=False)\n",
    "per_etf_sleep = widgets.FloatSlider(value=0.0, min=0.0, max=3.0, step=0.25, description=\"Sleep/sec per ETF\", readout_format=\".2f\")\n",
    "\n",
    "run_btn = widgets.Button(description=\"Run Look-Through\", button_style=\"success\")\n",
    "run_status = widgets.Output()\n",
    "\n",
    "# Overrides UI\n",
    "overrides_box = widgets.Output()\n",
    "save_overrides_btn = widgets.Button(description=\"Save ETF Overrides\", button_style=\"warning\")\n",
    "\n",
    "# Filters\n",
    "filter_sector = widgets.Dropdown(options=[\"(All)\"], value=\"(All)\", description=\"Sector:\", layout=widgets.Layout(width=\"360px\"))\n",
    "filter_country = widgets.Dropdown(options=[\"(All)\"], value=\"(All)\", description=\"Country:\", layout=widgets.Layout(width=\"360px\"))\n",
    "apply_filters_btn = widgets.Button(description=\"Apply Filters\", button_style=\"\")\n",
    "filters_status = widgets.Output()\n",
    "\n",
    "# Output area\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers for UI callbacks\n",
    "# -------------------------\n",
    "\n",
    "def _bytes_to_temp_csv(upload_widget: widgets.FileUpload, prefix: str) -> str:\n",
    "    if not upload_widget.value:\n",
    "        raise ValueError(\"No file uploaded.\")\n",
    "    item = list(upload_widget.value.values())[0]\n",
    "    content = item[\"content\"]\n",
    "    name = item.get(\"metadata\", {}).get(\"name\", f\"{prefix}.csv\")\n",
    "    tmp_path = DATA_DIR / f\"tmp_{prefix}_{now_ts()}_{name}\"\n",
    "    tmp_path.write_bytes(content)\n",
    "    return str(tmp_path)\n",
    "\n",
    "def _read_portfolio_from_upload_or_paste() -> pd.DataFrame:\n",
    "    if pf_upload.value:\n",
    "        path = _bytes_to_temp_csv(pf_upload, \"portfolio\")\n",
    "        df = pd.read_csv(path)\n",
    "        return df\n",
    "    # paste CSV\n",
    "    text = pf_paste.value.strip()\n",
    "    if not text:\n",
    "        raise ValueError(\"Paste area is empty and no portfolio CSV uploaded.\")\n",
    "    from io import StringIO\n",
    "    df = pd.read_csv(StringIO(text))\n",
    "    return df\n",
    "\n",
    "def _render_sm_status():\n",
    "    with sm_status:\n",
    "        clear_output()\n",
    "        master = STATE[\"master\"]\n",
    "        meta = None\n",
    "        if SECURITY_MASTER_META.exists():\n",
    "            try:\n",
    "                meta = json.loads(SECURITY_MASTER_META.read_text())\n",
    "            except Exception:\n",
    "                meta = None\n",
    "\n",
    "        print(f\"Security master rows: {len(master)}\")\n",
    "        if meta:\n",
    "            print(f\"Last refreshed: {meta.get('uploaded_at')}\")\n",
    "            print(f\"Raw copy: {meta.get('raw_copy')}\")\n",
    "            print(f\"Columns: {meta.get('columns')}\")\n",
    "        display(master.head(5))\n",
    "\n",
    "def _render_pf_status():\n",
    "    with pf_status:\n",
    "        clear_output()\n",
    "        df = STATE[\"portfolio_classified\"]\n",
    "        if df is None or len(df) == 0:\n",
    "            print(\"No portfolio loaded.\")\n",
    "            return\n",
    "        print(f\"Portfolio rows: {len(df)}\")\n",
    "        display(df)\n",
    "\n",
    "def _render_overrides_editor():\n",
    "    \"\"\"\n",
    "    Lightweight overrides editor: list tickers in current portfolio, with a checkbox per ticker.\n",
    "    Saves to data/overrides/asset_overrides.csv\n",
    "    \"\"\"\n",
    "    with overrides_box:\n",
    "        clear_output()\n",
    "        pf = STATE.get(\"portfolio_norm\")\n",
    "        if pf is None or len(pf) == 0:\n",
    "            print(\"Load a portfolio first to edit overrides.\")\n",
    "            return\n",
    "\n",
    "        current_overrides = load_asset_overrides().set_index(\"ticker_norm\")[\"is_etf\"].to_dict()\n",
    "        rows = []\n",
    "        widgets_map = {}\n",
    "\n",
    "        tickers = sorted(pf[\"ticker_norm\"].unique().tolist())\n",
    "\n",
    "        for t in tickers:\n",
    "            cb = widgets.Checkbox(value=bool(current_overrides.get(t, False)), description=t, indent=False)\n",
    "            widgets_map[t] = cb\n",
    "            rows.append(cb)\n",
    "\n",
    "        overrides_box._widgets_map = widgets_map  # stash for save\n",
    "        col = widgets.VBox(rows, layout=widgets.Layout(max_height=\"220px\", overflow=\"auto\", border=\"1px solid #ddd\", padding=\"6px\"))\n",
    "        display(widgets.HTML(\"<b>ETF Overrides (applies when portfolio input lacks is_etf)</b>\"))\n",
    "        display(col)\n",
    "\n",
    "def _update_filter_options(exposures: pd.DataFrame):\n",
    "    sectors = sorted([s for s in exposures[\"sector\"].dropna().unique().tolist() if str(s).strip() != \"\"])\n",
    "    countries = sorted([c for c in exposures[\"country\"].dropna().unique().tolist() if str(c).strip() != \"\"])\n",
    "    filter_sector.options = [\"(All)\"] + sectors\n",
    "    filter_country.options = [\"(All)\"] + countries\n",
    "    filter_sector.value = \"(All)\"\n",
    "    filter_country.value = \"(All)\"\n",
    "\n",
    "def _apply_filters_to_exposures(exposures: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = exposures.copy()\n",
    "    if filter_sector.value != \"(All)\":\n",
    "        df = df[df[\"sector\"] == filter_sector.value]\n",
    "    if filter_country.value != \"(All)\":\n",
    "        df = df[df[\"country\"] == filter_country.value]\n",
    "    return df\n",
    "\n",
    "def _render_outputs(exposures: pd.DataFrame):\n",
    "    with out:\n",
    "        clear_output()\n",
    "\n",
    "        if exposures is None or len(exposures) == 0:\n",
    "            print(\"No exposures to display.\")\n",
    "            return\n",
    "\n",
    "        by_company, by_sector, by_country, by_source = build_slices(exposures)\n",
    "        unknown = find_unknown_underlyings(exposures)\n",
    "\n",
    "        print(\"Top companies (look-through):\")\n",
    "        display(by_company.head(25))\n",
    "\n",
    "        print(\"\\nSector exposure:\")\n",
    "        display(by_sector)\n",
    "\n",
    "        print(\"\\nCountry exposure:\")\n",
    "        display(by_country)\n",
    "\n",
    "        print(\"\\nSource vehicles (direct vs ETF):\")\n",
    "        display(by_source)\n",
    "\n",
    "        if len(unknown) > 0:\n",
    "            print(\"\\nTickers not found in your Security Master (consider refreshing the master):\")\n",
    "            display(unknown.head(50))\n",
    "\n",
    "        # Charts\n",
    "        plot_bar(by_sector, \"sector\", \"total_exposure\", \"Exposure by Sector (Top 15)\", top_n=15)\n",
    "        plot_bar(by_country, \"country\", \"total_exposure\", \"Exposure by Country (Top 15)\", top_n=15)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Callbacks\n",
    "# -------------------------\n",
    "\n",
    "def on_sm_refresh(_):\n",
    "    with sm_status:\n",
    "        clear_output()\n",
    "        print(\"Refreshing security master...\")\n",
    "    try:\n",
    "        path = _bytes_to_temp_csv(sm_upload, \"security_master\")\n",
    "        STATE[\"master\"] = refresh_security_master_from_csv(path)\n",
    "        _render_sm_status()\n",
    "    except Exception as e:\n",
    "        with sm_status:\n",
    "            clear_output()\n",
    "            print(f\"Security master refresh failed: {e}\")\n",
    "\n",
    "def on_pf_template(_):\n",
    "    with pf_status:\n",
    "        clear_output()\n",
    "        print(\"Portfolio CSV template (copy/paste into a CSV file):\\n\")\n",
    "        print(\"ticker,dollars,is_etf\")\n",
    "        print(\"AAPL,5000,False\")\n",
    "        print(\"QQQ,8000,True\")\n",
    "        print(\"\\nAlternative template using shares + price_per_share:\\n\")\n",
    "        print(\"ticker,shares,price_per_share,is_etf\")\n",
    "        print(\"AAPL,20,190,False\")\n",
    "        print(\"QQQ,15,420,True\")\n",
    "        print(\"\\nAlternative template using percent (0..1) + Total $ in UI:\\n\")\n",
    "        print(\"ticker,percent,is_etf\")\n",
    "        print(\"AAPL,0.25,False\")\n",
    "        print(\"QQQ,0.40,True\")\n",
    "\n",
    "def on_pf_load(_):\n",
    "    try:\n",
    "        df = _read_portfolio_from_upload_or_paste()\n",
    "\n",
    "        tv = float(total_value.value) if total_value.value else None\n",
    "        # If any percent is present, require total value\n",
    "        if \"percent\" in [c.lower() for c in df.columns] and tv in (None, 0.0):\n",
    "            # only require if any non-null percent exists\n",
    "            tmp = df.copy()\n",
    "            tmp.columns = [c.strip().lower() for c in tmp.columns]\n",
    "            if \"percent\" in tmp.columns and tmp[\"percent\"].notna().any():\n",
    "                raise ValueError(\"Your portfolio includes 'percent'. Set Total $ (if %) in the UI (must be > 0).\")\n",
    "\n",
    "        pf_norm = normalize_portfolio_inputs(df, total_portfolio_value=(tv if tv and tv > 0 else None))\n",
    "        STATE[\"portfolio_raw\"] = df\n",
    "        STATE[\"portfolio_norm\"] = pf_norm\n",
    "\n",
    "        pf_classified = apply_etf_classification(pf_norm)\n",
    "\n",
    "        # Also enrich direct holdings with security master for nicer display\n",
    "        pf_classified = enrich_with_security_master(pf_classified, STATE[\"master\"], join_col=\"ticker_norm\")\n",
    "        STATE[\"portfolio_classified\"] = pf_classified\n",
    "\n",
    "        _render_pf_status()\n",
    "        _render_overrides_editor()\n",
    "\n",
    "    except Exception as e:\n",
    "        with pf_status:\n",
    "            clear_output()\n",
    "            print(f\"Portfolio load failed: {e}\")\n",
    "\n",
    "def on_save_overrides(_):\n",
    "    try:\n",
    "        wmap = getattr(overrides_box, \"_widgets_map\", {})\n",
    "        if not wmap:\n",
    "            raise ValueError(\"No overrides editor available. Load a portfolio first.\")\n",
    "        rows = [{\"ticker_norm\": t, \"is_etf\": bool(cb.value)} for t, cb in wmap.items()]\n",
    "        df = pd.DataFrame(rows)\n",
    "        save_asset_overrides(df)\n",
    "        with overrides_box:\n",
    "            print(\"\\nSaved overrides to:\", ASSET_OVERRIDES_CSV)\n",
    "    except Exception as e:\n",
    "        with overrides_box:\n",
    "            print(f\"\\nFailed to save overrides: {e}\")\n",
    "\n",
    "def on_run(_):\n",
    "    with run_status:\n",
    "        clear_output()\n",
    "        print(\"Running look-through...\")\n",
    "\n",
    "    try:\n",
    "        master = STATE[\"master\"]\n",
    "        if master is None or len(master) == 0:\n",
    "            raise ValueError(\"Security master is empty. Upload/refresh the Nasdaq screener CSV first.\")\n",
    "\n",
    "        pf = STATE.get(\"portfolio_norm\")\n",
    "        if pf is None or len(pf) == 0:\n",
    "            raise ValueError(\"No portfolio loaded. Upload or paste portfolio CSV, then click Load Portfolio.\")\n",
    "\n",
    "        # Re-apply classification in case overrides were saved/changed\n",
    "        pf_classified = apply_etf_classification(pf)\n",
    "        pf_classified = enrich_with_security_master(pf_classified, master, join_col=\"ticker_norm\")\n",
    "        STATE[\"portfolio_classified\"] = pf_classified\n",
    "\n",
    "        d = asof_date.value.strip() or today_str()\n",
    "        exp = build_lookthrough_exposures(\n",
    "            portfolio_df=pf_classified,\n",
    "            master_df=master,\n",
    "            refresh_missing_etf_holdings=bool(refresh_missing.value),\n",
    "            asof_date=d,\n",
    "            per_etf_sleep_seconds=float(per_etf_sleep.value),\n",
    "        )\n",
    "\n",
    "        STATE[\"exposures\"] = exp\n",
    "        _update_filter_options(exp)\n",
    "\n",
    "        filtered = _apply_filters_to_exposures(exp)\n",
    "        _render_outputs(filtered)\n",
    "\n",
    "        with run_status:\n",
    "            clear_output()\n",
    "            print(\"Done.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with run_status:\n",
    "            clear_output()\n",
    "            print(f\"Run failed: {e}\")\n",
    "\n",
    "def on_apply_filters(_):\n",
    "    try:\n",
    "        exp = STATE.get(\"exposures\")\n",
    "        if exp is None or len(exp) == 0:\n",
    "            with filters_status:\n",
    "                clear_output()\n",
    "                print(\"Nothing to filter yet. Run look-through first.\")\n",
    "            return\n",
    "        filtered = _apply_filters_to_exposures(exp)\n",
    "        _render_outputs(filtered)\n",
    "        with filters_status:\n",
    "            clear_output()\n",
    "            print(\"Filters applied.\")\n",
    "    except Exception as e:\n",
    "        with filters_status:\n",
    "            clear_output()\n",
    "            print(f\"Filter failed: {e}\")\n",
    "\n",
    "# Wire callbacks\n",
    "sm_refresh_btn.on_click(on_sm_refresh)\n",
    "pf_template_btn.on_click(on_pf_template)\n",
    "pf_load_btn.on_click(on_pf_load)\n",
    "save_overrides_btn.on_click(on_save_overrides)\n",
    "run_btn.on_click(on_run)\n",
    "apply_filters_btn.on_click(on_apply_filters)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Layout\n",
    "# -------------------------\n",
    "\n",
    "left = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Step 1 — Security Master</b>\"),\n",
    "    sm_upload,\n",
    "    sm_refresh_btn,\n",
    "    sm_status,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<b>Step 2 — Portfolio Input</b>\"),\n",
    "    pf_upload,\n",
    "    pf_template_btn,\n",
    "    total_value,\n",
    "    pf_paste,\n",
    "    pf_load_btn,\n",
    "    pf_status,\n",
    "])\n",
    "\n",
    "right = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Step 3 — ETF Overrides</b>\"),\n",
    "    overrides_box,\n",
    "    save_overrides_btn,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<b>Step 4 — Run</b>\"),\n",
    "    asof_date,\n",
    "    refresh_missing,\n",
    "    per_etf_sleep,\n",
    "    run_btn,\n",
    "    run_status,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<b>Step 5 — Slice / Dice Filters</b>\"),\n",
    "    widgets.HBox([filter_sector, filter_country]),\n",
    "    apply_filters_btn,\n",
    "    filters_status,\n",
    "])\n",
    "\n",
    "app = widgets.VBox([\n",
    "    title,\n",
    "    instructions,\n",
    "    widgets.HBox([left, right], layout=widgets.Layout(gap=\"16px\")),\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    out\n",
    "])\n",
    "\n",
    "# Initial renders\n",
    "_render_sm_status()\n",
    "_render_overrides_editor()\n",
    "\n",
    "display(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
