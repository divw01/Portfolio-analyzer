{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4241df6e",
   "metadata": {},
   "source": [
    "# Portfolio Look-Through Proof of Concept\n",
    "Using Financial Modeling Prep (FMP) API\n",
    "\n",
    "This notebook demonstrates a minimal but realistic core for a portfolio\n",
    "look-through application. It:\n",
    "1. Accepts a user portfolio with flexible inputs\n",
    "2. Normalizes holdings to dollar exposure\n",
    "3. Explodes ETFs into underlying constituents\n",
    "4. Enriches companies with sector, industry, and country\n",
    "5. Produces a unified exposure table suitable for slicing & dicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb7e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "246a3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CODE CELL 1: Imports + Config + Functions (put functions first) ---\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "API_KEY = \"yy9SAIQnhX9wB2ABVxXaRA9MxNxeLXPO\"\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "\n",
    "def fmp_get(endpoint: str, params: Dict[str, Any] | None = None):\n",
    "    \"\"\"Simple GET wrapper. Adds apikey automatically.\"\"\"\n",
    "    params = {} if params is None else dict(params)\n",
    "    params[\"apikey\"] = API_KEY\n",
    "    r = requests.get(f\"{BASE_URL}/{endpoint}\", params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def get_quote_short_prices(tickers: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"Fetches latest price per ticker using /quote-short.\"\"\"\n",
    "    prices = {}\n",
    "    for t in tickers.dropna().unique():\n",
    "        q = fmp_get(\"quote-short\", {\"symbol\": t})\n",
    "        # FMP returns a list; empty list can happen for invalid symbols\n",
    "        prices[t] = q[0][\"price\"] if q else None\n",
    "    return prices\n",
    "\n",
    "def get_profiles(tickers: pd.Series) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Fetches /profile for each ticker. Returns dict keyed by ticker.\"\"\"\n",
    "    out = {}\n",
    "    for t in tickers.dropna().unique():\n",
    "        try:\n",
    "            p = fmp_get(\"profile\", {\"symbol\": t})\n",
    "            out[t] = p[0] if p else {}\n",
    "        except Exception:\n",
    "            out[t] = {}\n",
    "    return out\n",
    "\n",
    "def normalize_portfolio_inputs(df: pd.DataFrame, total_portfolio_value: float | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inputs supported (per row):\n",
    "      - ticker (required)\n",
    "      - percent (optional; 0.0 to 1.0)\n",
    "      - shares (optional)\n",
    "      - price_per_share (optional)\n",
    "      - dollars (optional)\n",
    "    Normalizes to:\n",
    "      - price (market price if needed)\n",
    "      - position_value (dollars exposure)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    if \"ticker\" not in df.columns:\n",
    "        raise ValueError(\"Input must include a 'ticker' column.\")\n",
    "    df[\"ticker\"] = df[\"ticker\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # Market price only needed if shares are provided but price_per_share isn't\n",
    "    needs_market_price = df[\"shares\"].notna() & df.get(\"price_per_share\", pd.Series([None]*len(df))).isna()\n",
    "    tickers_needing_price = df.loc[needs_market_price, \"ticker\"]\n",
    "\n",
    "    market_prices = get_quote_short_prices(tickers_needing_price) if len(tickers_needing_price) else {}\n",
    "    df[\"market_price\"] = df[\"ticker\"].map(market_prices)\n",
    "\n",
    "    # Resolve row price\n",
    "    if \"price_per_share\" not in df.columns:\n",
    "        df[\"price_per_share\"] = pd.NA\n",
    "    df[\"price\"] = df[\"price_per_share\"].fillna(df[\"market_price\"])\n",
    "\n",
    "    # Compute position_value\n",
    "    def compute_value(row):\n",
    "        if pd.notna(row.get(\"dollars\")):\n",
    "            return float(row[\"dollars\"])\n",
    "        if pd.notna(row.get(\"shares\")):\n",
    "            if pd.isna(row.get(\"price\")):\n",
    "                return None\n",
    "            return float(row[\"shares\"]) * float(row[\"price\"])\n",
    "        if pd.notna(row.get(\"percent\")):\n",
    "            if total_portfolio_value is None:\n",
    "                raise ValueError(\"total_portfolio_value must be provided if any row uses 'percent'.\")\n",
    "            return float(row[\"percent\"]) * float(total_portfolio_value)\n",
    "        return None\n",
    "\n",
    "    df[\"position_value\"] = df.apply(compute_value, axis=1)\n",
    "\n",
    "    # Basic validation\n",
    "    if df[\"position_value\"].isna().any():\n",
    "        bad = df[df[\"position_value\"].isna()][[\"ticker\", \"percent\", \"shares\", \"price_per_share\", \"dollars\"]]\n",
    "        raise ValueError(f\"Could not compute position_value for some rows:\\n{bad.to_string(index=False)}\")\n",
    "\n",
    "    return df[[\"ticker\", \"percent\", \"shares\", \"price\", \"dollars\", \"position_value\"]]\n",
    "\n",
    "def classify_is_etf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds is_etf using /profile (field: isEtf).\"\"\"\n",
    "    df = df.copy()\n",
    "    profiles = get_profiles(df[\"ticker\"])\n",
    "    df[\"is_etf\"] = df[\"ticker\"].map(lambda t: bool(profiles.get(t, {}).get(\"isEtf\", False)))\n",
    "    df[\"asset_type\"] = df[\"is_etf\"].map(lambda x: \"ETF\" if x else \"Stock\")\n",
    "    return df\n",
    "\n",
    "def explode_lookthrough(portfolio_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a unified exposure table with:\n",
    "      source_ticker: original holding in portfolio\n",
    "      underlying_ticker: underlying exposure (same as source if not ETF)\n",
    "      exposure_value: $ exposure\n",
    "      source_type: ETF / Stock\n",
    "    For ETFs: uses /etf/holdings (asset, weightPercentage).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for _, r in portfolio_df.iterrows():\n",
    "        src = r[\"ticker\"]\n",
    "        src_type = r[\"asset_type\"]\n",
    "        pv = float(r[\"position_value\"])\n",
    "\n",
    "        if not r[\"is_etf\"]:\n",
    "            rows.append({\n",
    "                \"source_ticker\": src,\n",
    "                \"source_type\": src_type,\n",
    "                \"underlying_ticker\": src,\n",
    "                \"exposure_value\": pv\n",
    "            })\n",
    "        else:\n",
    "            holdings = fmp_get(\"etf/holdings\", {\"symbol\": src})\n",
    "            # If holdings empty, keep as unresolved ETF exposure (still useful for debugging)\n",
    "            if not holdings:\n",
    "                rows.append({\n",
    "                    \"source_ticker\": src,\n",
    "                    \"source_type\": src_type,\n",
    "                    \"underlying_ticker\": None,\n",
    "                    \"exposure_value\": pv\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            for h in holdings:\n",
    "                asset = h.get(\"asset\")\n",
    "                wt = h.get(\"weightPercentage\")\n",
    "                if asset is None or wt is None:\n",
    "                    continue\n",
    "                rows.append({\n",
    "                    \"source_ticker\": src,\n",
    "                    \"source_type\": src_type,\n",
    "                    \"underlying_ticker\": str(asset).upper().strip(),\n",
    "                    \"exposure_value\": pv * float(wt) / 100.0\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def enrich_underlyings(exposure_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds company_name, sector, industry, country for underlying_ticker using /profile.\"\"\"\n",
    "    df = exposure_df.copy()\n",
    "    tickers = df[\"underlying_ticker\"].dropna()\n",
    "    profiles = get_profiles(tickers)\n",
    "\n",
    "    def pick(t, key):\n",
    "        return profiles.get(t, {}).get(key)\n",
    "\n",
    "    df[\"company_name\"] = df[\"underlying_ticker\"].map(lambda t: pick(t, \"companyName\"))\n",
    "    df[\"sector\"] = df[\"underlying_ticker\"].map(lambda t: pick(t, \"sector\"))\n",
    "    df[\"industry\"] = df[\"underlying_ticker\"].map(lambda t: pick(t, \"industry\"))\n",
    "    df[\"country\"] = df[\"underlying_ticker\"].map(lambda t: pick(t, \"country\"))\n",
    "    return df\n",
    "\n",
    "def build_slices(exposures: pd.DataFrame):\n",
    "    \"\"\"Convenience: returns (by_company, by_sector, by_country, by_source_vehicle).\"\"\"\n",
    "    by_company = (\n",
    "        exposures.dropna(subset=[\"underlying_ticker\"])\n",
    "        .groupby([\"underlying_ticker\", \"company_name\"], dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\", \"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "    )\n",
    "\n",
    "    by_sector = (\n",
    "        exposures.groupby(\"sector\", dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\", \"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "    )\n",
    "\n",
    "    by_country = (\n",
    "        exposures.groupby(\"country\", dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\", \"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "    )\n",
    "\n",
    "    by_source_vehicle = (\n",
    "        exposures.groupby([\"source_ticker\", \"source_type\"], dropna=False)\n",
    "        .agg(total_exposure=(\"exposure_value\", \"sum\"))\n",
    "        .sort_values(\"total_exposure\", ascending=False)\n",
    "    )\n",
    "\n",
    "    return by_company, by_sector, by_country, by_source_vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc882a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/n9j2tnf56sz57xdgr922njrw0000gn/T/ipykernel_19321/2037043709.py:69: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"price\"] = df[\"price_per_share\"].fillna(df[\"market_price\"])\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://financialmodelingprep.com/stable/etf/holdings?symbol=SPY&apikey=yy9SAIQnhX9wB2ABVxXaRA9MxNxeLXPO",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m portfolio = classify_is_etf(portfolio)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 3) Look-through explosion\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m lookthrough = \u001b[43mexplode_lookthrough\u001b[49m\u001b[43m(\u001b[49m\u001b[43mportfolio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 4) Enrich underlyings\u001b[39;00m\n\u001b[32m     22\u001b[39m exposures = enrich_underlyings(lookthrough)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mexplode_lookthrough\u001b[39m\u001b[34m(portfolio_df)\u001b[39m\n\u001b[32m    118\u001b[39m     rows.append({\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msource_ticker\u001b[39m\u001b[33m\"\u001b[39m: src,\n\u001b[32m    120\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msource_type\u001b[39m\u001b[33m\"\u001b[39m: src_type,\n\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33munderlying_ticker\u001b[39m\u001b[33m\"\u001b[39m: src,\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexposure_value\u001b[39m\u001b[33m\"\u001b[39m: pv\n\u001b[32m    123\u001b[39m     })\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     holdings = \u001b[43mfmp_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43metf/holdings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msymbol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# If holdings empty, keep as unresolved ETF exposure (still useful for debugging)\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m holdings:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mfmp_get\u001b[39m\u001b[34m(endpoint, params)\u001b[39m\n\u001b[32m     16\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mapikey\u001b[39m\u001b[33m\"\u001b[39m] = API_KEY\n\u001b[32m     17\u001b[39m r = requests.get(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, params=params, timeout=\u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://financialmodelingprep.com/stable/etf/holdings?symbol=SPY&apikey=yy9SAIQnhX9wB2ABVxXaRA9MxNxeLXPO"
     ]
    }
   ],
   "source": [
    "# --- CODE CELL 2: Input + Run Pipeline + Outputs ---\n",
    "\n",
    "# Example portfolio input (replace with CSV later)\n",
    "portfolio_input = pd.DataFrame([\n",
    "    {\"ticker\": \"AAPL\", \"shares\": 20},\n",
    "    {\"ticker\": \"MSFT\", \"dollars\": 3000},\n",
    "    {\"ticker\": \"SPY\", \"percent\": 0.40},\n",
    "])\n",
    "\n",
    "TOTAL_PORTFOLIO_VALUE = 20000  # required if using percent weights\n",
    "\n",
    "# 1) Normalize\n",
    "portfolio = normalize_portfolio_inputs(portfolio_input, total_portfolio_value=TOTAL_PORTFOLIO_VALUE)\n",
    "\n",
    "# 2) Classify ETF vs stock\n",
    "portfolio = classify_is_etf(portfolio)\n",
    "\n",
    "# 3) Look-through explosion\n",
    "lookthrough = explode_lookthrough(portfolio)\n",
    "\n",
    "# 4) Enrich underlyings\n",
    "exposures = enrich_underlyings(lookthrough)\n",
    "\n",
    "# 5) Slices\n",
    "by_company, by_sector, by_country, by_source_vehicle = build_slices(exposures)\n",
    "\n",
    "print(\"Portfolio (normalized):\")\n",
    "display(portfolio)\n",
    "\n",
    "print(\"\\nUnified Look-Through Exposures (sample):\")\n",
    "display(exposures.sort_values(\"exposure_value\", ascending=False).head(25))\n",
    "\n",
    "print(\"\\nExposure by Company:\")\n",
    "display(by_company.head(25))\n",
    "\n",
    "print(\"\\nExposure by Sector:\")\n",
    "display(by_sector)\n",
    "\n",
    "print(\"\\nExposure by Country:\")\n",
    "display(by_country)\n",
    "\n",
    "print(\"\\nExposure by Source Vehicle (ETF vs Stock):\")\n",
    "display(by_source_vehicle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
